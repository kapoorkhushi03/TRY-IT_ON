{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapoorkhushi03/TRY-IT_ON/blob/main/OpenPose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYaA0JOPSQ02",
        "outputId": "5451bb47-465b-4f3e-b1c5-b91ce5151544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'human-pose-estimation-opencv'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)\u001b[K\rremote: Counting objects:  10% (2/20)\u001b[K\rremote: Counting objects:  15% (3/20)\u001b[K\rremote: Counting objects:  20% (4/20)\u001b[K\rremote: Counting objects:  25% (5/20)\u001b[K\rremote: Counting objects:  30% (6/20)\u001b[K\rremote: Counting objects:  35% (7/20)\u001b[K\rremote: Counting objects:  40% (8/20)\u001b[K\rremote: Counting objects:  45% (9/20)\u001b[K\rremote: Counting objects:  50% (10/20)\u001b[K\rremote: Counting objects:  55% (11/20)\u001b[K\rremote: Counting objects:  60% (12/20)\u001b[K\rremote: Counting objects:  65% (13/20)\u001b[K\rremote: Counting objects:  70% (14/20)\u001b[K\rremote: Counting objects:  75% (15/20)\u001b[K\rremote: Counting objects:  80% (16/20)\u001b[K\rremote: Counting objects:  85% (17/20)\u001b[K\rremote: Counting objects:  90% (18/20)\u001b[K\rremote: Counting objects:  95% (19/20)\u001b[K\rremote: Counting objects: 100% (20/20)\u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 20 (delta 5), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (20/20), 10.09 MiB | 32.49 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/human-pose-estimation-opencv\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/misbah4064/human-pose-estimation-opencv.git\n",
        "%cd /content/human-pose-estimation-opencv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Define the body parts and their corresponding indices\n",
        "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
        "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
        "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
        "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
        "\n",
        "# Define the pairs of body parts that form a pose\n",
        "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
        "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
        "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
        "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
        "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
        "\n",
        "# Define input dimensions for the network\n",
        "width = 368\n",
        "height = 368\n",
        "inWidth = width\n",
        "inHeight = height\n",
        "\n",
        "# Load the pre-trained pose detection model\n",
        "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
        "thr = 0.2  # Confidence threshold for the detected keypoints\n",
        "\n",
        "# Function to detect poses in a frame\n",
        "def poseDetector(frame):\n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "\n",
        "    # Prepare the input blob for the network\n",
        "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
        "    out = net.forward()\n",
        "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
        "\n",
        "    assert(len(BODY_PARTS) == out.shape[1])\n",
        "\n",
        "    points = []\n",
        "    # Iterate over the body parts to extract keypoints\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "        # Slice heatmap of corresponding body part\n",
        "        heatMap = out[0, i, :, :]\n",
        "\n",
        "        # Find the maximum confidence and corresponding location\n",
        "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
        "        x = (frameWidth * point[0]) / out.shape[3]\n",
        "        y = (frameHeight * point[1]) / out.shape[2]\n",
        "        points.append((int(x), int(y)) if conf > thr else None)\n",
        "\n",
        "    # Connect keypoints to form poses\n",
        "    for pair in POSE_PAIRS:\n",
        "        partFrom = pair[0]\n",
        "        partTo = pair[1]\n",
        "        assert(partFrom in BODY_PARTS)\n",
        "        assert(partTo in BODY_PARTS)\n",
        "\n",
        "        idFrom = BODY_PARTS[partFrom]\n",
        "        idTo = BODY_PARTS[partTo]\n",
        "\n",
        "        if points[idFrom] and points[idTo]:\n",
        "            # Draw line between keypoints\n",
        "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
        "            # Draw keypoints\n",
        "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "\n",
        "    return frame\n",
        "\n",
        "input = cv.imread(\"/content/human-pose-estimation-opencv/your_input_image.jpg\")\n",
        "output = poseDetector(input)\n",
        "cv2_imshow(output)\n"
      ],
      "metadata": {
        "id": "CrZ9nm0USWsR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}